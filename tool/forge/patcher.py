# forge/patcher.py
# -*- coding: utf-8 -*-

"""
The "Forge" python library for the P2K ELF SDK toolchain.

Python: 3.10+
License: MIT
Authors: EXL, MotoFan.Ru
Date: 15-Dec-2023
Version: 1.0
"""

import shutil
import logging

from pathlib import Path

from .hexer import int2hex
from .hexer import int2hex_r
from .hexer import hex2int_r
from .hexer import arrange16
from .hexer import is_hex_string
from .types import PatchDict
from .types import PatchDictNone
from .hexer import normalize_hex_address
from .filesystem import check_files_if_exists
from .filesystem import check_files_extensions
from .types import CsConfigParser
from .utilities import get_current_datetime_formatted


def sort_patch_dict(unsorted: PatchDict) -> PatchDict:
	return {key: unsorted[key] for key in sorted(unsorted)}


def patch_size_of_hex_str(hex_str: str) -> int:
	length: int = len(hex_str)
	length_good: int = int(len(hex_str) / 2)
	if length % 2 != 0:
		logging.warning(f'Wrong and odd size "{length}" of patch!')
		logging.warning(f'Will truncate it to "{length}/2={length_good}" size!')
	return length_good


def check_if_address_beyond_file_size(address: int, file_size: int, patch_size: int) -> bool:
	offset_size: int = address + patch_size
	if (address > file_size) or (offset_size > file_size):
		e_a: str = int2hex(address)
		e_p: str = int2hex(patch_size)
		e_o: str = int2hex(offset_size)
		e_f: str = int2hex(file_size)
		logging.warning(f'Read/Write position beyond: "addr={e_a}", "patch={e_p}" "offset={e_o}", "file_size={e_f}"')
		return False
	return True


def generate_fpa(fw: str, author: str, desc: str, patterns: PatchDict, fpa: Path, undos: PatchDictNone = None) -> bool:
	if len(patterns) > 0:
		with fpa.open(mode='w', newline='\r\n') as f_o:
			f_o.write('; Patch file was generated by "forge" library.\n')
			f_o.write('; Source Code: https://github.com/MotoFanRu/P2K-ELF-SDK\n')
			f_o.write(f'; Timestamp: {get_current_datetime_formatted()}\n\n')
			f_o.write('[Patch_Info]\n')
			f_o.write(f'SW_Ver={fw}\n')
			f_o.write(f'Author={author}\n')
			f_o.write(f'Description={desc}\n')
			f_o.write('\n[Patch_Code]\n')
			for addr, value in patterns.items():
				f_o.write(f'{addr}: {value}\n')
			if (undos is not None) and (len(undos) > 0):
				f_o.write('\n[Patch_Undo]\n')
				for addr, undo in undos.items():
					f_o.write(f'{addr}: {undo}\n')
		return True
	else:
		logging.error('Patch data is empty.')
		return False


def undo_data(addr: int, hex_data: str, undo: Path, log: bool = False) -> str | None:
	if check_files_if_exists([undo]) and check_files_extensions([undo], ['bin', 'smg']):
		with undo.open(mode='rb') as f_i:
			p_size: int = patch_size_of_hex_str(hex_data)
			if check_if_address_beyond_file_size(addr, undo.stat().st_size, p_size):
				if log:
					logging.info(f'Read: "{int2hex(addr)}" undo value, data size: "{int2hex(p_size)}, {p_size}".')
				f_i.seek(addr)
				undo_str: str = f_i.read(p_size).hex().upper()
			else:
				if log:
					logging.warning(f'Read beyond: "{int2hex(addr)}", write "{int2hex(p_size)}, {p_size}" FF-bytes.')
				undo_str: str = 'FF' * p_size
			return undo_str
	return None


def bin2fpa(fw: str, author: str, desc: str, addr: int, binary: Path, fpa: Path, undo: Path | None = None) -> bool:
	if check_files_if_exists([binary]) and check_files_extensions([binary], ['bin']):
		with binary.open(mode='rb') as f_i:
			hex_str: str = f_i.read().hex().upper()
			return hex2fpa(fw, author, desc, addr, hex_str, fpa, undo)
	return False


def hex2fpa(fw: str, author: str, desc: str, addr: int, hex_data: str, fpa: Path, undo: Path | None = None) -> bool:
	patch_size: int = patch_size_of_hex_str(hex_data)
	if patch_size % 2 != 0:
		logging.warning(f'Patch size "{int2hex(patch_size)} {patch_size}" is not even.')
	hex_patch: str = hex_data[:(patch_size * 2)]  # Truncate patch size.
	new_size: int = patch_size_of_hex_str(hex_patch)
	if patch_size != new_size:
		logging.warning(f'Patch was truncated from "{patch_size}" to "{new_size}".')
	patch_dict: PatchDict = {int2hex_r(addr): hex_patch}
	if undo is not None:
		undo_dict: PatchDict = {int2hex_r(addr): undo_data(addr, hex_patch, undo)}
		if undo_dict.get(int2hex_r(addr)) is not None:
			return generate_fpa(fw, author, desc, patch_dict, fpa, undo_dict)
	return generate_fpa(fw, author, desc, patch_dict, fpa)


def get_fpa_patch_values(config: CsConfigParser, section: str, is_code: bool = False) -> PatchDictNone:
	values: PatchDict = {}
	if config.has_section(section):
		for option in config[section]:
			value: str = config[section][option]
			if is_code:
				option: str = normalize_hex_address(option, True)
			values[option] = value
			logging.debug(f'{option} : {value}')
		if len(values) > 0:
			return values
	return None


def read_fpa_patch_to_config_model(fpa: Path) -> CsConfigParser | None:
	config: CsConfigParser = CsConfigParser()
	try:
		config.read(fpa)
		return config
	except Exception as error:
		logging.error(f'Cannot read patch: {error}')
		return None


def fpa2bin(fpa: Path, binary: Path) -> bool:
	if check_files_extensions([binary], ['bin']):
		config: CsConfigParser = read_fpa_patch_to_config_model(fpa)
		if config is None:
			return False
		values: PatchDictNone = get_fpa_patch_values(config, 'Patch_Code', True)
		if values is not None:
			for address, value in values.items():
				binary_chunk_path: Path = binary.with_stem(f'{binary.stem}_{address}')
				logging.info(f'Writing "{binary_chunk_path}" binary file.')
				with binary_chunk_path.open(mode='wb') as f_o:
					f_o.write(bytes.fromhex(value))
			return True
	return False


def unite_dicts_to_one(*dicts: PatchDict) -> PatchDictNone:
	united_dict: PatchDict = {}
	duplicates: set[str] = set()
	for d in dicts:
		for key, value in d.items():
			if key in united_dict:
				logging.error(f'Something wrong with patches, there is duplicate address values "{key}".')
				duplicates.add(key)
			united_dict[key] = value
	if (len(duplicates) > 0) or (len(united_dict) == 0):
		return None
	return united_dict


def unite_fpa_patches(fw: str, author: str, desc: str, patches: list[Path], result: Path) -> bool:
	united_code_list: list[PatchDict] = []
	united_undo_list: list[PatchDict] = []
	for patch in patches:
		config: CsConfigParser = read_fpa_patch_to_config_model(patch)
		if config is None:
			return False
		code_p: PatchDictNone = get_fpa_patch_values(config, 'Patch_Code', True)
		if code_p is not None:
			united_code_list.append(code_p)
		undo_p: PatchDictNone = get_fpa_patch_values(config, 'Patch_Undo', True)
		if undo_p is not None:
			united_undo_list.append(undo_p)
	if len(united_code_list) > 0:
		united_code_dict: PatchDictNone = unite_dicts_to_one(*united_code_list)
		united_undo_dict: PatchDictNone = unite_dicts_to_one(*united_undo_list)
		if united_code_dict is not None:
			united_code_dict: PatchDictNone = sort_patch_dict(united_code_dict)
		if united_undo_dict is not None:
			united_undo_dict: PatchDictNone = sort_patch_dict(united_undo_dict)
		return generate_fpa(fw, author, desc, united_code_dict, result, united_undo_dict)
	return False


def apply_fpa_patch(firmware: Path, fpa: Path, backup: bool, validating: bool, revert: bool = False) -> bool:
	files_here: bool = check_files_if_exists([firmware, fpa])
	extensions_ok: bool = check_files_extensions([firmware], ['bin', 'smg']) and check_files_extensions([fpa], ['fpa'])
	if files_here and extensions_ok:
		section_patches: str = 'Patch_Undo' if revert else 'Patch_Code'
		section_undo_patches: str = 'Patch_Code' if revert else 'Patch_Undo'
		config: CsConfigParser = read_fpa_patch_to_config_model(fpa)
		if config is None:
			return False
		file_size: int = firmware.stat().st_size
		if validating:
			undo_patches: PatchDictNone = get_fpa_patch_values(config, section_undo_patches, True)
			if undo_patches is not None:
				with firmware.open(mode='rb') as f_i:
					for address, value in undo_patches.items():
						p_addr: int = hex2int_r(address)
						p_size: int = patch_size_of_hex_str(value)
						undo: str = value.upper()
						if check_if_address_beyond_file_size(p_addr, file_size, p_size):
							f_i.seek(p_addr)
							hex_data: str = f_i.read(patch_size_of_hex_str(value)).hex().upper()
						else:
							hex_data: str = 'FF' * p_size
						if hex_data == undo:
							logging.info(f'Patch "{int2hex(p_addr)}" valid, data size: "{int2hex(p_size)}, {p_size}".')
						else:
							logging.info(f'Patch "{int2hex(p_addr)}" not valid with undo values {hex_data}=={undo}.')
							return False
			else:
				logging.error(f'Validation mode failed, undo values are not present in the "{fpa}" patch.')
				return False
		patches: PatchDictNone = get_fpa_patch_values(config, section_patches, True)
		if patches is not None:
			if backup:
				backup_file: Path = firmware.with_stem(f'{firmware.stem}_backup')
				logging.info(f'Create backup file from "{firmware}" to "{backup_file}".')
				shutil.copy(firmware, backup_file)
			with firmware.open(mode='r+b') as f_o:
				for address, value in patches.items():
					p_addr: int = hex2int_r(address)
					p_size: int = patch_size_of_hex_str(value)
					if not check_if_address_beyond_file_size(p_addr, file_size, p_size):
						f_o.seek(file_size)
						p_pad: int = arrange16(p_addr + p_size) - file_size
						h_p: str = int2hex(p_pad)
						h_s: str = int2hex(file_size)
						logging.info(f'Add FF-bytes filled extra space to "{firmware}", size: "{file_size}".')
						logging.info(f'\tOffset "{h_s}": filled with "{h_p}, {p_pad}" FF-bytes.')
						f_o.write(b'\xFF' * p_pad)
					f_o.seek(p_addr)
					logging.info(f'Write: "{int2hex(p_addr)}" patch, data size: "{int2hex(p_size)}, {p_size}".')
					f_o.write(bytes.fromhex(value))
			return True
	return False


def generate_and_append_undo_values_to_fpa(firmware: Path, fpa: Path) -> bool:
	files_here: bool = check_files_if_exists([firmware, fpa])
	extensions_ok: bool = check_files_extensions([firmware], ['bin', 'smg']) and check_files_extensions([fpa], ['fpa'])
	if files_here and extensions_ok:
		config: CsConfigParser = read_fpa_patch_to_config_model(fpa)
		if config is None:
			return False
		patches: PatchDictNone = get_fpa_patch_values(config, 'Patch_Code', True)
		undo_patches: PatchDictNone = get_fpa_patch_values(config, 'Patch_Undo', True)
		if undo_patches:
			logging.error(f'Undo values already present in the "{fpa}" patch.')
			return False
		if patches is not None:
			with fpa.open(mode='a', newline='\r\n') as f_o:
				f_o.write('\n[Patch_Undo]\n')
				for address, value in patches.items():
					p_addr: int = hex2int_r(address)
					hex_data: str = undo_data(p_addr, value, firmware, True)
					if hex_data:
						f_o.write(f'{int2hex_r(p_addr)}: {hex_data}\n')

			# Validate written values again.
			config_validate: CsConfigParser = read_fpa_patch_to_config_model(fpa)
			if config is not None:
				patches_validate: PatchDictNone = get_fpa_patch_values(config_validate, 'Patch_Code', True)
				undo_patches_validate: PatchDictNone = get_fpa_patch_values(config_validate, 'Patch_Undo', True)
				return (patches_validate is not None) and (undo_patches_validate is not None)
	return False


def patch_binary_file(binary_file: Path, old_bytes: str, new_bytes: str, dry: bool = False) -> int:
	if check_files_if_exists([binary_file]) and check_files_extensions([binary_file], ['bin', 'smg']):
		old_bytes: str = old_bytes.replace('\\x', '')
		new_bytes: str = new_bytes.replace('\\x', '')

		if old_bytes == new_bytes:
			logging.warning('Skip patch. The patch data matches the original.')
			logging.warning(f'Old: "{old_bytes}"')
			logging.warning(f'New: "{new_bytes}"')
			return -1

		if not is_hex_string(old_bytes):
			logging.warning('Wrong HEX-string with non-HEX data.')
			logging.warning(f'old_bytes: "{old_bytes}"')
			return -1

		if not is_hex_string(new_bytes):
			logging.warning('Wrong HEX-string with non-HEX data.')
			logging.warning(f'new_bytes: "{new_bytes}"')
			return -1

		found: int = 0
		write_to: int = 0
		chunk_size: int = 4096
		old_bytes_sequence: bytes = bytes.fromhex(old_bytes)
		new_bytes_sequence: bytes = bytes.fromhex(new_bytes)

		if len(old_bytes_sequence) == len(new_bytes_sequence):
			with binary_file.open('rb+') as f_io:
				chunk: bytes = f_io.read(chunk_size)
				while chunk:
					offset: int = chunk.find(old_bytes_sequence)
					if offset >= 0:
						found = found + 1
						write_to = f_io.tell() - len(chunk) + offset
						logging.info(f'Match found on "{int2hex(write_to)}": "{old_bytes}".')
					chunk = f_io.read(chunk_size)
				if found == 1:
					f_io.seek(write_to)
					if not dry:
						logging.info(f'Apply patch to "{binary_file}" file:')
						logging.info(f'Old: "{old_bytes}"')
						logging.info(f'New: "{new_bytes}"')
						f_io.write(new_bytes_sequence)
					return write_to
				elif found > 1:
					logging.error(f'Too many ({found}) matches of "{old_bytes}" pattern in "{binary_file}" file.')
				else:
					logging.error(f'Pattern "{old_bytes}" not found in "{binary_file}" file.')
		else:
			logging.error(f'Length of "{old_bytes}" and "{new_bytes}" patterns does not match.')
	return -1


def patch_binary_file_res(binary_file: Path, old_bytes: str, new_bytes: str) -> bool:
	return patch_binary_file(binary_file, old_bytes, new_bytes) > 0


def patch_text_file_template(p_i: Path, p_o: Path, replaces: dict[str, str], replace_all: bool = False) -> bool:
	if check_files_if_exists([p_i]):
		text: str = p_i.read_text()
		for template, replacement in replaces.items():
			if replace_all:
				text = text.replace(template, replacement)
			else:
				text = text.replace(template, replacement, 1)
		try:
			p_o.write_text(text, newline='\r\n')
			return True
		except IOError as error:
			logging.error(f'An I/O error occurred with {p_o} file: {error}')
	return False
